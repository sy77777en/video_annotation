#!/usr/bin/env python3
"""
Caption to JSON API - Aligned with Original Code

This API converts captions to JSON format using LLM, with retry logic.
It uses the task_info_summary.json file generated by extract_prompts_and_keys.py.

ALIGNMENT WITH ORIGINAL CODE:
- Uses same LLM interface as llm module (ChatGPT, Gemini)
- Default model: "gpt-5.2" with temperature=0.0
- API key from secrets["openai_key"] (matches original)
- Can also load from .env file containing: openai_key = "sk-..."

Usage:
    from caption_to_json_api import CaptionToJsonAPI, convert_caption_to_json
    
    # Simple usage
    result = convert_caption_to_json(
        caption="A person walking in a park",
        task="subject",
        secrets={"openai_key": "sk-..."}  # Note: openai_key, not OPENAI_API_KEY
    )
"""

import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from abc import ABC, abstractmethod


# =============================================================================
# ENVIRONMENT LOADING
# =============================================================================

def load_env_file(env_path: str = ".env") -> Dict[str, str]:
    """
    Load environment variables from .env file.
    Format: key = "value"
    """
    env_vars = {}
    env_file = Path(env_path)
    
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    env_vars[key] = value
    
    return env_vars


# =============================================================================
# LLM IMPLEMENTATIONS (Matching Original llm Module)
# =============================================================================

class BaseLLM(ABC):
    """Base class for LLM implementations"""
    
    @abstractmethod
    def generate(self, prompt: str, temperature: float = 0.0, **kwargs) -> str:
        """Generate a response from the LLM"""
        pass


class ChatGPT(BaseLLM):
    """ChatGPT implementation matching llm/chatgpt.py"""
    
    def __init__(self, model: str = "gpt-4o-2024-08-06", api_key: str = None):
        valid_models = [
            "gpt-5-mini", "gpt-5.1", "gpt-5.2", 
            "gpt-4.1-2025-04-14", "gpt-4o-2024-08-06", 
            "gpt-4o-mini-2024-07-18", "o1-2024-12-17"
        ]
        assert model in valid_models, f"Model {model} not in {valid_models}"
        
        self.api_key = api_key
        os.environ["OPENAI_API_KEY"] = self.api_key
        
        try:
            from openai import OpenAI
            self.client = OpenAI()
        except ImportError:
            raise ImportError("openai package required. Install with: pip install openai")
        
        self.model = model
    
    def generate(self, prompt: str, temperature: float = 0.0, **kwargs) -> str:
        """Generate text from a prompt (text-only, matching original)"""
        messages = [{"role": "user", "content": prompt}]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            **kwargs
        )
        
        return response.choices[0].message.content.strip()


class Gemini(BaseLLM):
    """Gemini implementation matching llm/gemini.py"""
    
    def __init__(self, model: str = "gemini-2.5-pro", api_key: str = None):
        valid_models = [
            "gemini-2.5-pro", "gemini-3-pro-preview"
        ]
        assert model in valid_models, f"Model {model} not in {valid_models}"
        
        self.api_key = api_key
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            self.client = genai.GenerativeModel(model)
        except ImportError:
            raise ImportError("google-generativeai required. Install with: pip install google-generativeai")
        
        self.model = model
    
    def generate(self, prompt: str, temperature: float = 0.0, **kwargs) -> str:
        """Generate text from a prompt"""
        response = self.client.generate_content(prompt)
        return response.text if response.text else ""


# Model registry (matching original ALL_MODELS)
ALL_MODELS = {
    "ChatGPT": [
        "gpt-4.1-2025-04-14",
        "gpt-4o-2024-08-06",
        "gpt-5-mini",
        "gpt-5.1",
        "gpt-5.2",
    ],
    "Gemini": [
        "gemini-2.5-pro",
        "gemini-3-pro-preview",
    ],
}


def get_llm(model: str = "gpt-4o-2024-08-06", secrets: Optional[Dict[str, Any]] = None) -> BaseLLM:
    """
    Get LLM instance (matching original llm.get_llm).
    
    Args:
        model: Model name
        secrets: Dict containing API keys. Expected keys:
            - openai_key for ChatGPT models (NOT OPENAI_API_KEY)
            - gemini_key for Gemini models
    
    Returns:
        BaseLLM instance
    """
    secrets = secrets or {}
    
    # Try to load from .env if secrets not provided
    if not secrets:
        env_vars = load_env_file()
        if env_vars:
            secrets = env_vars
    
    if model in ALL_MODELS["ChatGPT"]:
        api_key = secrets.get("openai_key") or os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("openai_key not found in secrets, .env, or environment")
        return ChatGPT(model=model, api_key=api_key)
    
    elif model in ALL_MODELS["Gemini"]:
        api_key = secrets.get("gemini_key") or os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("gemini_key not found in secrets or environment")
        return Gemini(model=model, api_key=api_key)
    
    else:
        raise ValueError(f"Invalid LLM model '{model}'")


def get_all_llms() -> List[str]:
    """Get list of all available LLM model names"""
    model_names = []
    for model_type, models in ALL_MODELS.items():
        model_names.extend(models)
    return model_names


# =============================================================================
# TASK CONFIGURATION
# =============================================================================

TASK_FULL_TO_SHORT = {
    "subject_description": "subject",
    "scene_composition_dynamics": "scene",
    "subject_motion_dynamics": "motion",
    "spatial_framing_dynamics": "spatial",
    "camera_framing_dynamics": "camera",
    "color_composition_dynamics": "color",
    "lighting_setup_dynamics": "lighting",
    "lighting_effects_dynamics": "effects"
}

TASK_SHORT_TO_FULL = {v: k for k, v in TASK_FULL_TO_SHORT.items()}


# =============================================================================
# RESULT DATA CLASS
# =============================================================================

@dataclass
class ConversionResult:
    """Result of caption to JSON conversion"""
    success: bool
    json_data: Optional[Dict[str, Any]]
    raw_response: str
    error_message: Optional[str]
    attempts: int
    valid_json: bool
    has_all_keys: bool
    has_only_expected_keys: bool
    missing_keys: List[str]
    extra_keys: List[str]


# =============================================================================
# MAIN API CLASS
# =============================================================================

class CaptionToJsonAPI:
    """
    API for converting captions to JSON format using LLM.
    
    RETRY LOGIC:
    - Max retries: 3 (default)
    - Retry conditions:
      1. Empty response from LLM ‚Üí retry
      2. Invalid JSON parsing ‚Üí retry with hint
      3. Missing required keys ‚Üí retry with specific feedback about which keys missing
      4. Extra unexpected keys ‚Üí retry with specific feedback about which keys extra
    - Success condition: Valid JSON with ALL and ONLY expected keys
    
    Example retry flow:
    Attempt 1: Returns {"type": "person"} but expected ["type", "appearance", "wardrobe"]
               ‚Üí Missing keys: ["appearance", "wardrobe"]
    Attempt 2: Adds retry hint: "Missing required keys: ['appearance', 'wardrobe']"
               Returns {"type": "person", "appearance": "...", "wardrobe": "...", "extra": "..."}
               ‚Üí Extra keys: ["extra"]
    Attempt 3: Adds retry hint: "Unexpected keys found: ['extra']"
               Returns {"type": "person", "appearance": "...", "wardrobe": "..."}
               ‚Üí Success!
    """
    
    def __init__(
        self, 
        task_info_path: Optional[str] = None,
        secrets: Optional[Dict] = None
    ):
        """
        Initialize the API.
        
        Args:
            task_info_path: Path to task_info_summary.json file.
                           If None, tries to find it in json_policy/task_info_summary.json
            secrets: Secrets dict for LLM authentication.
                    Expected keys: openai_key (not OPENAI_API_KEY)
        """
        self.secrets = secrets or {}
        
        # Try to load from .env if secrets not provided
        if not self.secrets:
            env_vars = load_env_file(".env")
            if env_vars:
                self.secrets = env_vars
        
        # Load task info from provided path or default location
        self.task_info = self._load_task_info(task_info_path)
        
        if not self.task_info:
            print("WARNING: task_info_summary.json not found. Run extract_prompts_and_keys.py first.")
    
    def _load_task_info(self, task_info_path: Optional[str] = None) -> Dict[str, Any]:
        """
        Load task info from task_info_summary.json
        
        Args:
            task_info_path: Path to task_info_summary.json.
                           If None, tries default locations.
        """
        if task_info_path:
            # Use provided path
            if Path(task_info_path).exists():
                with open(task_info_path, 'r') as f:
                    return json.load(f)
            else:
                print(f"WARNING: Provided task_info_path not found: {task_info_path}")
                return {}
        
        # Try default locations
        possible_paths = [
            Path("json_policy/task_info_summary.json"),
            Path("../json_policy/task_info_summary.json"),
            Path.cwd() / "json_policy" / "task_info_summary.json",
        ]
        
        for path in possible_paths:
            if path.exists():
                with open(path, 'r') as f:
                    return json.load(f)
        
        return {}
    
    def get_available_tasks(self) -> List[str]:
        """Get list of available task short names"""
        return list(self.task_info.keys())
    
    def get_json_keys_for_task(self, task: str) -> List[str]:
        """Get the expected JSON keys for a task (extracted from template)"""
        short_name = TASK_FULL_TO_SHORT.get(task, task)
        
        if short_name in self.task_info:
            return self.task_info[short_name].get("json_keys", [])
        return []
    
    def get_json_structure_for_task(self, task: str) -> Dict[str, Any]:
        """Get the JSON structure for a task (extracted from template)"""
        short_name = TASK_FULL_TO_SHORT.get(task, task)
        
        if short_name in self.task_info:
            return self.task_info[short_name].get("json_structure") or \
                   self.task_info[short_name].get("json_policy", {})
        return {}
    
    def get_prompt_template_for_task(self, task: str) -> str:
        """Get the default prompt template for a task"""
        short_name = TASK_FULL_TO_SHORT.get(task, task)
        
        if short_name in self.task_info:
            template = self.task_info[short_name].get("default_template")
            if template:
                return template
        
        raise ValueError(f"No template found for task '{task}'. Run extract_prompts_and_keys.py first.")
    
    def _clean_response(self, response: str) -> str:
        """Clean LLM response to extract JSON (matching test_llm.py)"""
        response = response.strip()
        
        # Remove markdown code blocks
        if response.startswith('```json'):
            response = response[7:]
        elif response.startswith('```'):
            response = response[3:]
        
        if response.endswith('```'):
            response = response[:-3]
        
        return response.strip()
    
    def _validate_json_keys(
        self, 
        json_data: Dict[str, Any], 
        expected_keys: List[str]
    ) -> Tuple[bool, bool, List[str], List[str]]:
        """Validate that JSON has all and only the expected keys"""
        if not isinstance(json_data, dict):
            return False, False, expected_keys, []
        
        actual_keys = set(json_data.keys())
        expected_set = set(expected_keys)
        
        missing_keys = list(expected_set - actual_keys)
        extra_keys = list(actual_keys - expected_set)
        
        has_all_keys = len(missing_keys) == 0
        has_only_expected_keys = len(extra_keys) == 0
        
        return has_all_keys, has_only_expected_keys, missing_keys, extra_keys
    
    def convert(
        self,
        caption: str,
        prompt: Optional[str] = None,
        json_keys: Optional[List[str]] = None,
        task: Optional[str] = None,
        model: str = "gpt-5.2",  # Default model matching original
        temperature: float = 0.0,  # Default temperature matching original
        max_retries: int = 3,
        verbose: bool = False
    ) -> ConversionResult:
        """Convert a caption to JSON format using LLM with retry logic"""
        # Normalize task name
        if task:
            task = TASK_FULL_TO_SHORT.get(task, task)
        
        # Get prompt template
        if prompt is None:
            if task is None:
                raise ValueError("Either 'prompt' or 'task' must be provided")
            prompt = self.get_prompt_template_for_task(task)
        
        # Get expected JSON keys
        if json_keys is None:
            if task is None:
                raise ValueError("Either 'json_keys' or 'task' must be provided")
            json_keys = self.get_json_keys_for_task(task)
        
        # Validate prompt has placeholder
        if "{caption}" not in prompt:
            raise ValueError("Prompt must contain {caption} placeholder")
        
        # Get LLM instance
        llm = get_llm(model=model, secrets=self.secrets)
        
        # Build final prompt
        final_prompt = prompt.replace("{caption}", caption)
        
        # Retry loop
        last_error = None
        last_response = ""
        
        for attempt in range(1, max_retries + 1):
            if verbose:
                print(f"Attempt {attempt}/{max_retries}...")
            
            try:
                # Generate response
                response = llm.generate(final_prompt, temperature=temperature)
                
                if not response or not response.strip():
                    last_error = "LLM returned empty response"
                    continue
                
                # Clean response
                cleaned_response = self._clean_response(response)
                last_response = cleaned_response
                
                # Try to parse JSON
                try:
                    json_data = json.loads(cleaned_response)
                except json.JSONDecodeError as e:
                    last_error = f"Invalid JSON: {e}"
                    
                    # Add retry hint to prompt
                    if attempt < max_retries:
                        retry_hint = f"\n\nPrevious response was not valid JSON. Error: {e}\nPlease return ONLY valid JSON without any additional text or markdown."
                        final_prompt = prompt.replace("{caption}", caption) + retry_hint
                    continue
                
                # Validate keys
                has_all_keys, has_only_expected_keys, missing_keys, extra_keys = \
                    self._validate_json_keys(json_data, json_keys)
                
                if verbose:
                    print(f"  Valid JSON: True")
                    print(f"  Has all keys: {has_all_keys}")
                    print(f"  Has only expected keys: {has_only_expected_keys}")
                    if missing_keys:
                        print(f"  Missing keys: {missing_keys}")
                    if extra_keys:
                        print(f"  Extra keys: {extra_keys}")
                
                # Check if we have all and only expected keys
                if has_all_keys and has_only_expected_keys:
                    return ConversionResult(
                        success=True,
                        json_data=json_data,
                        raw_response=cleaned_response,
                        error_message=None,
                        attempts=attempt,
                        valid_json=True,
                        has_all_keys=True,
                        has_only_expected_keys=True,
                        missing_keys=[],
                        extra_keys=[]
                    )
                
                # Keys validation failed, prepare retry
                last_error = f"Key validation failed. Missing: {missing_keys}, Extra: {extra_keys}"
                
                if attempt < max_retries:
                    # Build retry prompt with specific feedback
                    key_feedback = []
                    if missing_keys:
                        key_feedback.append(f"Missing required keys: {missing_keys}")
                    if extra_keys:
                        key_feedback.append(f"Unexpected keys found: {extra_keys}")
                    
                    retry_hint = f"""

Previous response had key issues:
{chr(10).join(key_feedback)}

Please return JSON with EXACTLY these keys: {json_keys}
Return ONLY valid JSON without any additional text."""
                    final_prompt = prompt.replace("{caption}", caption) + retry_hint
                    
            except Exception as e:
                last_error = str(e)
                if verbose:
                    print(f"  Error: {last_error}")
        
        # All retries exhausted - try to return partial result
        try:
            json_data = json.loads(last_response)
            has_all_keys, has_only_expected_keys, missing_keys, extra_keys = \
                self._validate_json_keys(json_data, json_keys)
            
            return ConversionResult(
                success=False,
                json_data=json_data,
                raw_response=last_response,
                error_message=last_error,
                attempts=max_retries,
                valid_json=True,
                has_all_keys=has_all_keys,
                has_only_expected_keys=has_only_expected_keys,
                missing_keys=missing_keys,
                extra_keys=extra_keys
            )
        except:
            return ConversionResult(
                success=False,
                json_data=None,
                raw_response=last_response,
                error_message=last_error,
                attempts=max_retries,
                valid_json=False,
                has_all_keys=False,
                has_only_expected_keys=False,
                missing_keys=json_keys,
                extra_keys=[]
            )


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================

def convert_caption_to_json(
    caption: str,
    task: str,
    task_info_path: Optional[str] = None,
    model: str = "gpt-5.2",
    temperature: float = 0.0,
    max_retries: int = 3,
    secrets: Optional[Dict] = None,
    verbose: bool = False
) -> ConversionResult:
    """
    Simple function to convert a caption to JSON.
    
    Args:
        caption: The caption text to convert
        task: Task name (e.g., "subject", "camera", "motion", etc.)
        task_info_path: Path to task_info_summary.json. If None, uses default location.
        model: LLM model to use (default: "gpt-5.2")
        temperature: Temperature for generation (default: 0.0)
        max_retries: Maximum retry attempts (default: 3)
        secrets: Secrets dict. Expected: openai_key (not OPENAI_API_KEY)
        verbose: Print debug info
    
    Returns:
        ConversionResult
    """
    api = CaptionToJsonAPI(task_info_path=task_info_path, secrets=secrets)
    return api.convert(
        caption=caption,
        task=task,
        model=model,
        temperature=temperature,
        max_retries=max_retries,
        verbose=verbose
    )


def batch_convert_from_json(
    json_file: str,
    task: str,
    task_info_path: Optional[str] = None,
    model: str = "gpt-5.2",
    temperature: float = 0.0,
    max_retries: int = 3,
    secrets: Optional[Dict] = None,
    output_file: Optional[str] = None,
    verbose: bool = False
) -> List[Dict[str, Any]]:
    """
    Batch convert captions from a JSON file.
    
    Input JSON format:
    [
        {"caption": "A person walking...", "video_id": "video_001"},
        {"caption": "Another caption...", "video_id": "video_002"}
    ]
    
    Or:
    {
        "video_001": {"caption": "A person walking..."},
        "video_002": {"caption": "Another caption..."}
    }
    
    Returns list of results with video_id and conversion result.
    """
    # Load JSON file
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    # Normalize to list format
    if isinstance(data, dict):
        items = [{"video_id": k, "caption": v.get("caption", v)} 
                 for k, v in data.items()]
    else:
        items = data
    
    # Initialize API
    api = CaptionToJsonAPI(task_info_path=task_info_path, secrets=secrets)
    
    # Process each caption
    results = []
    for i, item in enumerate(items, 1):
        video_id = item.get("video_id", f"item_{i}")
        caption = item.get("caption", "")
        
        if not caption:
            print(f"Skipping {video_id}: no caption")
            continue
        
        print(f"\n[{i}/{len(items)}] Processing {video_id}...")
        
        result = api.convert(
            caption=caption,
            task=task,
            model=model,
            temperature=temperature,
            max_retries=max_retries,
            verbose=verbose
        )
        
        results.append({
            "video_id": video_id,
            "caption": caption,
            "success": result.success,
            "json_data": result.json_data,
            "attempts": result.attempts,
            "error": result.error_message,
            "missing_keys": result.missing_keys,
            "extra_keys": result.extra_keys
        })
        
        if result.success:
            print(f"  ‚úÖ Success in {result.attempts} attempt(s)")
        else:
            print(f"  ‚ùå Failed after {result.attempts} attempts: {result.error_message}")
    
    # Save output if requested
    if output_file:
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nüíæ Results saved to {output_file}")
    
    return results


# =============================================================================
# EXAMPLE CAPTIONS FOR EACH TASK
# =============================================================================

EXAMPLE_CAPTIONS = {
    "camera": """The video predominantly features a slight high-angle perspective, looking downward at the computer. It maintains a shallow depth of field, with the screen in the foreground remaining in sharp focus, clearly displaying the male characters. Background elements within the physical scene such as walls, windows, and the ground are only slightly blurred, while the screen's background is distinctly blurred. The camera is unsteady, with noticeable shaking, and occasionally tilts downward as the person interacts with a USB connection on the screen.""",
    
    "subject": """The video presents a dynamic, continuous sequence from a first-person perspective, featuring a man with light skin and dark hair displayed on a futuristic, semi-transparent screen. He is shown from the shoulders up, encased in a glowing digital bubble, wearing a grey V-neck shirt and a necklace, and speaking directly to the viewer with subtle shifts in expression. The screen rests on a cylindrical metallic base with several ports glowing in pink, orange, blue, and white, some of which have devices plugged into them. As the video progresses, a smaller circular frame appears, showcasing a Black man in a red hoodie with a focused expression. Midway through, the hand of the person filming, wearing a red sleeve, interacts with the screen's base, unplugging and replugging several USB devices. The background visible through the screen is a blurred cityscape.""",
    
    "motion": """A man is seen on a circular screen, speaking and moving his head slightly. The background shows a blurred cityscape with buildings. The man continues to speak and move his head, and a hand appears from the bottom of the screen, removing an orange USB drive from the screen's port, reinserting it, and then removing a different pink USB drive. The screen changes due to the USB drive being swapped. The man on the screen continues to speak, and a smaller circular frame with a Black man in a red hoodie appears at the bottom right of the screen.""",
    
    "scene": """The video presents a first-person POV shot set indoors, featuring a modern, high-tech environment with floor-to-ceiling windows. A large, transparent screen displays a video call interface with a circular view of an outdoor urban setting, showing buildings and a clear sky. The time of day appears to be daytime, with bright natural light illuminating the scene. The screen also includes a smaller circular inset showing another person, suggesting a conversation. The room is sleek and futuristic, with colorful walls in shades of blue, pink, and white, and a low shelving unit on the left side, emphasizing digital communication technology.""",
    
    "spatial": """The video captures a first-person perspective within a modern, high-tech indoor setting. In the center of the scene, a large, transparent screen dominates the foreground, displaying a circular digital interface with a man in a gray hoodie and necklace. This man occupies the central area of the circular frame, which is positioned in the middle of the screen. The background features a colorful wall with shades of blue, pink, and white, occupying a significant portion of the scene. On the left side of the screen, in the middle ground, a low shelving unit holds various items, including what appears to be a drone. Additionally, there is a partially visible floor-to-ceiling window on the left side of the background. As the video progresses, a hand wearing a red sleeve enters from the bottom of the frame, interacting with the screen's controls located at the bottom edge. Simultaneously, a smaller circular inset appears near the bottom right corner of the screen, showing another individual in a red hoodie. The camera remains at eye level throughout, maintaining a consistent viewpoint relative to the subjects and objects in the scene. The overall spatial arrangement emphasizes the interaction between the viewer and the digital interface, with the screen acting as the focal point.""",
}


# =============================================================================
# MAIN
# =============================================================================

def main():
    """Main CLI interface"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Caption to JSON API - Convert captions to structured JSON",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Convert single caption
  python caption_to_json_api.py --caption "A person walking" --task subject
  
  # Batch convert from JSON file
  python caption_to_json_api.py --json-file captions.json --task camera --output results.json
  
  # Run demo on all example captions
  python caption_to_json_api.py --demo
  
  # Try specific example
  python caption_to_json_api.py --demo --task subject --verbose
        """
    )
    
    # Input options
    input_group = parser.add_mutually_exclusive_group()
    input_group.add_argument("--caption", type=str, help="Single caption to convert")
    input_group.add_argument("--json-file", type=str, help="JSON file with captions to batch convert")
    input_group.add_argument("--demo", action="store_true", help="Run demo on example captions")
    
    # Task and model options
    parser.add_argument("--task", type=str, default="subject",
                       choices=list(TASK_SHORT_TO_FULL.keys()),
                       help="Task type (default: subject)")
    parser.add_argument("--task-info-path", type=str, default=None,
                       help="Path to task_info_summary.json (default: auto-detect in json_policy/)")
    parser.add_argument("--model", type=str, default="gpt-5.2",
                       help="LLM model to use (default: gpt-5.2)")
    parser.add_argument("--temperature", type=float, default=0.0,
                       help="Temperature for generation (default: 0.0)")
    parser.add_argument("--max-retries", type=int, default=3,
                       help="Maximum retry attempts (default: 3)")
    
    # Output options
    parser.add_argument("--output", type=str, help="Output JSON file (for batch mode)")
    parser.add_argument("--verbose", action="store_true", help="Verbose output")
    
    # API key options
    parser.add_argument("--openai-key", type=str, help="OpenAI API key (or use .env file)")
    parser.add_argument("--gemini-key", type=str, help="Gemini API key (or use .env file)")
    
    args = parser.parse_args()
    
    # Setup secrets
    secrets = {}
    if args.openai_key:
        secrets["openai_key"] = args.openai_key
    if args.gemini_key:
        secrets["gemini_key"] = args.gemini_key
    
    # If no secrets provided, try to load from .env
    if not secrets:
        env_vars = load_env_file()
        if env_vars:
            secrets = env_vars
    
    # Handle different modes
    if args.demo:
        # Run demo on example captions
        print("=" * 80)
        print("DEMO: Running API on Example Captions")
        print("=" * 80)
        
        # Check if task_info exists
        api = CaptionToJsonAPI(task_info_path=args.task_info_path, secrets=secrets)
        if not api.task_info:
            print("\n‚ùå task_info_summary.json not found!")
            print("   Run extract_prompts_and_keys.py first to generate it.")
            return
        
        # If task specified, only run that task
        if args.task:
            tasks_to_run = [args.task] if args.task in EXAMPLE_CAPTIONS else []
            if not tasks_to_run:
                print(f"‚ùå No example caption for task '{args.task}'")
                print(f"Available tasks: {list(EXAMPLE_CAPTIONS.keys())}")
                return
        else:
            # Run all tasks
            tasks_to_run = list(EXAMPLE_CAPTIONS.keys())
        
        for task in tasks_to_run:
            caption = EXAMPLE_CAPTIONS[task]
            
            print(f"\n{'‚îÄ' * 80}")
            print(f"TASK: {task.upper()}")
            print(f"{'‚îÄ' * 80}")
            print(f"Caption: {caption[:100]}...")
            print(f"Model: {args.model}, Temperature: {args.temperature}, Max Retries: {args.max_retries}")
            print()
            
            result = convert_caption_to_json(
                caption=caption,
                task=task,
                task_info_path=args.task_info_path,
                model=args.model,
                temperature=args.temperature,
                max_retries=args.max_retries,
                secrets=secrets,
                verbose=args.verbose
            )
            
            if result.success:
                print(f"‚úÖ SUCCESS in {result.attempts} attempt(s)")
                print(f"\nGenerated JSON:")
                print(json.dumps(result.json_data, indent=2))
            else:
                print(f"‚ùå FAILED after {result.attempts} attempts")
                print(f"Error: {result.error_message}")
                if result.missing_keys:
                    print(f"Missing keys: {result.missing_keys}")
                if result.extra_keys:
                    print(f"Extra keys: {result.extra_keys}")
                if result.json_data:
                    print(f"\nPartial JSON:")
                    print(json.dumps(result.json_data, indent=2))
        
        print(f"\n{'=' * 80}")
        print("Demo complete!")
        print("=" * 80)
    
    elif args.json_file:
        # Batch mode
        print("=" * 80)
        print("BATCH MODE: Converting captions from JSON file")
        print("=" * 80)
        print(f"Input: {args.json_file}")
        print(f"Task: {args.task}")
        print(f"Model: {args.model}")
        print(f"Temperature: {args.temperature}")
        print(f"Max Retries: {args.max_retries}")
        if args.output:
            print(f"Output: {args.output}")
        print()
        
        results = batch_convert_from_json(
            json_file=args.json_file,
            task=args.task,
            task_info_path=args.task_info_path,
            model=args.model,
            temperature=args.temperature,
            max_retries=args.max_retries,
            secrets=secrets,
            output_file=args.output,
            verbose=args.verbose
        )
        
        # Print summary
        success_count = sum(1 for r in results if r["success"])
        print(f"\n{'=' * 80}")
        print(f"SUMMARY: {success_count}/{len(results)} successful conversions")
        print("=" * 80)
    
    elif args.caption:
        # Single caption mode
        print("=" * 80)
        print("SINGLE CAPTION MODE")
        print("=" * 80)
        print(f"Caption: {args.caption}")
        print(f"Task: {args.task}")
        print(f"Model: {args.model}")
        print(f"Temperature: {args.temperature}")
        print(f"Max Retries: {args.max_retries}")
        print()
        
        result = convert_caption_to_json(
            caption=args.caption,
            task=args.task,
            task_info_path=args.task_info_path,
            model=args.model,
            temperature=args.temperature,
            max_retries=args.max_retries,
            secrets=secrets,
            verbose=args.verbose
        )
        
        if result.success:
            print(f"‚úÖ SUCCESS in {result.attempts} attempt(s)")
            print(f"\nGenerated JSON:")
            print(json.dumps(result.json_data, indent=2))
        else:
            print(f"‚ùå FAILED after {result.attempts} attempts")
            print(f"Error: {result.error_message}")
            if result.missing_keys:
                print(f"Missing keys: {result.missing_keys}")
            if result.extra_keys:
                print(f"Extra keys: {result.extra_keys}")
    
    else:
        # No mode specified - run demo by default
        print("=" * 80)
        print("Caption to JSON API - Running Demo on Example Captions")
        print("=" * 80)
        print("\nNo arguments provided - running demo by default")
        print("Use --help to see all options")
        print()
        
        # Check if task_info_summary.json exists
        api = CaptionToJsonAPI(task_info_path=args.task_info_path, secrets=secrets)
        
        if not api.task_info:
            print("‚ùå task_info_summary.json not found!")
            print("   Run extract_prompts_and_keys.py first to generate it.")
            return
        
        print(f"‚úÖ Loaded task info for {len(api.task_info)} tasks")
        print(f"Model: {args.model}, Temperature: {args.temperature}, Max Retries: {args.max_retries}")
        print()
        
        # Run demo on one example from each task
        for task_name in ["subject", "camera", "motion", "scene", "spatial"]:
            if task_name not in EXAMPLE_CAPTIONS:
                continue
                
            caption_text = EXAMPLE_CAPTIONS[task_name]
            
            print(f"{'‚îÄ' * 80}")
            print(f"Task: {task_name.upper()}")
            print(f"{'‚îÄ' * 80}")
            print(f"Caption: {caption_text[:100]}...")
            print()
            
            try:
                result = api.convert(
                    caption=caption_text,
                    task=task_name,
                    model=args.model,
                    temperature=args.temperature,
                    max_retries=args.max_retries,
                    verbose=args.verbose
                )
                
                if result.success:
                    print(f"‚úÖ SUCCESS in {result.attempts} attempt(s)")
                    print(f"\nGenerated JSON:")
                    print(json.dumps(result.json_data, indent=2))
                else:
                    print(f"‚ùå FAILED after {result.attempts} attempt(s)")
                    print(f"Error: {result.error_message}")
                    if result.missing_keys:
                        print(f"Missing keys: {result.missing_keys}")
                    if result.extra_keys:
                        print(f"Extra keys: {result.extra_keys}")
                        
            except Exception as e:
                print(f"‚ùå Error: {e}")
            
            print()
        
        print("=" * 80)
        print("Demo complete! Use --help for more options.")
        print("=" * 80)


if __name__ == "__main__":
    main()