#!/usr/bin/env python3
"""
Test Caption to JSON API - Streamlit Interface

This is a simplified version of test_llm.py that ONLY uses the caption_to_json_api.py module.
It allows you to verify that the API produces the same results as the original test_llm.py.

Run with:
    streamlit run test_caption_to_json_api.py

Requirements:
    - streamlit
    - caption_to_json_api.py (must be in same directory or Python path)
    - task_info_summary.json (generated by extract_prompts_and_keys.py)
"""

import streamlit as st
import json
from pathlib import Path
from typing import Dict, Any, List, Optional

# Import the self-contained API
from caption_to_json_api import (
    CaptionToJsonAPI, 
    convert_caption_to_json,
    get_all_llms,
    TASK_FULL_TO_SHORT,
    TASK_SHORT_TO_FULL,
    ConversionResult
)


# Page configuration
st.set_page_config(
    page_title="Test Caption to JSON API",
    page_icon="ðŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded"
)


def get_root_path() -> Path:
    """Find the project root path"""
    current = Path(__file__).parent
    if (current / "json_policy").exists():
        return current
    elif (current.parent / "json_policy").exists():
        return current.parent
    return Path.cwd()


def main():
    st.title("ðŸ§ª Test Caption to JSON API")
    st.markdown("""
    This interface tests the **self-contained** `caption_to_json_api.py` module.
    
    **How it works:**
    1. `extract_prompts_and_keys.py` generates `task_info_summary.json` with the EXACT templates from test_llm.py
    2. This interface uses those pre-generated templates via `caption_to_json_api.py`
    3. The prompts are IDENTICAL to what test_llm.py would use
    """)
    
    # Initialize API
    root_path = get_root_path()
    
    try:
        api = CaptionToJsonAPI(root_path=root_path, secrets=dict(st.secrets))
    except Exception as e:
        st.error(f"Failed to initialize API: {e}")
        st.info("Make sure `task_info_summary.json` exists. Run `extract_prompts_and_keys.py` first.")
        return
    
    if not api.task_info:
        st.error("âŒ task_info_summary.json not found!")
        st.info("Run `python extract_prompts_and_keys.py` first to generate the task info file.")
        return
    
    # Sidebar - Task Selection
    st.sidebar.title("âš™ï¸ Settings")
    
    available_tasks = api.get_available_tasks()
    
    if not available_tasks:
        st.sidebar.error("No tasks found in task_info_summary.json")
        return
    
    # Task selection
    selected_task = st.sidebar.selectbox(
        "Select Task:",
        available_tasks,
        format_func=lambda x: f"{x} ({TASK_SHORT_TO_FULL.get(x, x)})"
    )
    
    # Show task info
    if selected_task:
        task_info = api.task_info.get(selected_task, {})
        json_keys = task_info.get("json_keys", [])
        json_policy = task_info.get("json_policy", {})
        template_source = task_info.get("template_source", "unknown")
        using_custom = task_info.get("using_custom_default", False)
        custom_name = task_info.get("custom_default_name")
        
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ðŸ“‹ Task Info")
        st.sidebar.write(f"**Expected JSON Keys:** {json_keys}")
        st.sidebar.write(f"**Template Source:** {template_source}")
        
        if using_custom:
            st.sidebar.success(f"Using custom template: {custom_name}")
        else:
            st.sidebar.info("Using code-generated template")
    
    # LLM selection
    st.sidebar.markdown("---")
    available_llms = get_all_llms()
    selected_llm = st.sidebar.selectbox(
        "Select LLM Model:",
        available_llms,
        index=available_llms.index("gpt-4o") if "gpt-4o" in available_llms else 0
    )
    
    # Max retries
    max_retries = st.sidebar.slider("Max Retries:", 1, 5, 3)
    
    # Verbose mode
    verbose = st.sidebar.checkbox("Verbose Output", value=False)
    
    # Main content area
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ðŸ“ Input Caption")
        
        # Sample captions for testing
        sample_captions = {
            "subject": "A young woman in her mid-20s with long brown hair and blue eyes, wearing a red summer dress and white sneakers, walking confidently through a sunlit park.",
            "scene": "A cozy coffee shop interior with exposed brick walls, warm ambient lighting from vintage Edison bulbs, wooden tables and chairs scattered throughout, a long bar counter with an espresso machine, and large windows showing a rainy street outside.",
            "motion": "The protagonist runs quickly across the frame from left to right, jumping over obstacles with athletic grace while her hair flows behind her in the wind.",
            "spatial": "The subject is positioned in the center-left of the frame, with a shallow depth of field creating a soft bokeh background. The composition follows the rule of thirds.",
            "camera": "The camera slowly pushes in on the subject while simultaneously tilting up, creating a dramatic reveal effect. The movement is smooth and controlled.",
        }
        
        default_caption = sample_captions.get(selected_task, "Enter your caption here...")
        
        caption_input = st.text_area(
            "Enter caption to convert:",
            value=default_caption,
            height=150,
            key="caption_input"
        )
        
        # Show prompt template
        with st.expander("ðŸ“œ View Prompt Template (from task_info_summary.json)", expanded=False):
            prompt_template = api.get_prompt_template_for_task(selected_task)
            st.code(prompt_template, language="text")
            
            st.markdown("---")
            st.markdown("**Template Source:** " + task_info.get("template_source", "unknown"))
            
            # Option to use custom prompt
            use_custom_prompt = st.checkbox("Use custom prompt instead", key="use_custom")
            
            if use_custom_prompt:
                custom_prompt = st.text_area(
                    "Custom Prompt (must contain {caption}):",
                    value=prompt_template,
                    height=400,
                    key="custom_prompt"
                )
            else:
                custom_prompt = None
        
        # Show caption instruction
        with st.expander("ðŸ“– Caption Instruction (from task_info_summary.json)", expanded=False):
            caption_instruction = task_info.get("caption_instruction", "N/A")
            st.text(caption_instruction)
        
        # Show expected JSON structure (from template, not json_policy.json)
        with st.expander("ðŸ”‘ Expected JSON Structure (extracted from template)", expanded=False):
            # Use json_structure (from template) if available, else json_policy
            json_structure = task_info.get("json_structure") or task_info.get("json_policy", {})
            st.json(json_structure)
            st.write(f"**Top-level keys (for validation):** {json_keys}")
        
        # Generate button
        if st.button("ðŸš€ Generate JSON", type="primary", use_container_width=True):
            if not caption_input.strip():
                st.error("Please enter a caption")
            else:
                with st.spinner(f"Generating JSON with {selected_llm}..."):
                    try:
                        # Determine which prompt to use
                        prompt_to_use = custom_prompt if (use_custom_prompt and custom_prompt) else None
                        
                        result = api.convert(
                            caption=caption_input,
                            prompt=prompt_to_use,
                            task=selected_task,
                            model=selected_llm,
                            max_retries=max_retries,
                            verbose=verbose
                        )
                        
                        # Store result in session state
                        st.session_state["last_result"] = result
                        st.session_state["last_task"] = selected_task
                        st.session_state["last_caption"] = caption_input
                        
                    except Exception as e:
                        st.error(f"Error: {e}")
                        import traceback
                        st.code(traceback.format_exc())
    
    with col2:
        st.subheader("ðŸ“¤ Output JSON")
        
        # Display results
        if "last_result" in st.session_state:
            result = st.session_state["last_result"]
            
            # Status indicators
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                if result.success:
                    st.success(f"âœ… Success ({result.attempts} attempt(s))")
                else:
                    st.error(f"âŒ Failed ({result.attempts} attempt(s))")
            
            with col_b:
                if result.valid_json:
                    st.success("âœ… Valid JSON")
                else:
                    st.error("âŒ Invalid JSON")
            
            with col_c:
                if result.has_all_keys and result.has_only_expected_keys:
                    st.success("âœ… Keys OK")
                else:
                    st.warning("âš ï¸ Key Issues")
            
            # Key validation details
            if result.missing_keys:
                st.warning(f"**Missing keys:** {result.missing_keys}")
            if result.extra_keys:
                st.warning(f"**Extra keys:** {result.extra_keys}")
            
            # Error message
            if result.error_message:
                st.error(f"**Error:** {result.error_message}")
            
            # JSON output
            st.markdown("---")
            st.markdown("### Generated JSON:")
            
            if result.json_data:
                formatted_json = json.dumps(result.json_data, indent=2)
                st.code(formatted_json, language="json")
                
                # Copy button
                st.download_button(
                    label="ðŸ“‹ Download JSON",
                    data=formatted_json,
                    file_name=f"{st.session_state.get('last_task', 'output')}.json",
                    mime="application/json"
                )
            else:
                st.warning("No valid JSON generated")
                if result.raw_response:
                    st.markdown("**Raw response:**")
                    st.code(result.raw_response)
        
        else:
            st.info("Click 'Generate JSON' to convert the caption")
    
    # Comparison section
    st.markdown("---")
    st.subheader("ðŸ” Compare with Original test_llm.py")
    
    with st.expander("How to Verify Prompts are Identical", expanded=False):
        st.markdown("""
        ### Verification Steps:
        
        1. **Compare prompt templates:**
           - Open both interfaces side by side
           - Expand "View Prompt Template" in both
           - The templates should be **character-for-character identical**
        
        2. **Key differences to check:**
           
           | Task | Special Instructions |
           |------|---------------------|
           | `camera` | Instruction #7: "No period after each caption" |
           | `subject` | Instructions #7-9: No periods + wardrobe/appearance restrictions |
           | `motion` | Instructions #7-8: No periods + subject action focus |
           | Others | Instruction #2: "Preserve all important information from the caption" (no "with all the keywords and details") |
        
        3. **Verify caption instruction:**
           - The "Caption Instruction" section should match what `caption_policy.prompt_generator` produces
        
        4. **Check for custom templates:**
           - If `json_policy/templates/{task}/default.txt` exists, it should reference a custom template
           - Both interfaces should use the same custom template
        
        ### What extract_prompts_and_keys.py does:
        
        ```
        1. Loads json_policy.json â†’ json_policy
        2. Gets caption instruction from caption_policy module â†’ caption_instruction  
        3. Checks for custom default template in templates/{task}/default.txt
        4. If custom exists: loads that template file
        5. If not: generates template using EXACT same code as test_llm.py
        6. Saves everything to task_info_summary.json
        ```
        
        The API then simply loads from task_info_summary.json, guaranteeing identical prompts.
        """)
    
    # Batch testing section
    st.markdown("---")
    st.subheader("ðŸ“Š Batch Testing")
    
    with st.expander("Run Batch Test", expanded=False):
        st.markdown("Test multiple captions at once to verify consistency.")
        
        batch_captions = st.text_area(
            "Enter captions (one per line):",
            height=150,
            placeholder="Caption 1\nCaption 2\nCaption 3"
        )
        
        if st.button("ðŸš€ Run Batch Test", key="batch_test"):
            if not batch_captions.strip():
                st.error("Please enter at least one caption")
            else:
                captions = [c.strip() for c in batch_captions.split("\n") if c.strip()]
                
                results = []
                progress = st.progress(0)
                status = st.empty()
                
                for i, caption in enumerate(captions):
                    status.text(f"Processing {i+1}/{len(captions)}...")
                    
                    try:
                        result = api.convert(
                            caption=caption,
                            task=selected_task,
                            model=selected_llm,
                            max_retries=max_retries,
                            verbose=False
                        )
                        results.append({
                            "caption": caption[:50] + "..." if len(caption) > 50 else caption,
                            "success": result.success,
                            "valid_json": result.valid_json,
                            "has_all_keys": result.has_all_keys,
                            "attempts": result.attempts,
                            "error": result.error_message
                        })
                    except Exception as e:
                        results.append({
                            "caption": caption[:50] + "..." if len(caption) > 50 else caption,
                            "success": False,
                            "valid_json": False,
                            "has_all_keys": False,
                            "attempts": 0,
                            "error": str(e)
                        })
                    
                    progress.progress((i + 1) / len(captions))
                
                status.text("Done!")
                
                # Display results as table
                st.dataframe(results)
                
                # Summary
                success_count = sum(1 for r in results if r["success"])
                st.write(f"**Success rate:** {success_count}/{len(results)} ({100*success_count/len(results):.1f}%)")


if __name__ == "__main__":
    main()